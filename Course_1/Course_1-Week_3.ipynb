{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T11:29:29.372042Z",
     "start_time": "2021-07-15T11:29:25.565059Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T12:14:02.159502Z",
     "start_time": "2021-07-14T12:13:47.866028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4947 - accuracy: 0.8256\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.3724 - accuracy: 0.8659\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3343 - accuracy: 0.8785\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.3121 - accuracy: 0.8847s - loss: 0.3109 - accuracy: \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2932 - accuracy: 0.8919\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.3438 - accuracy: 0.8752\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images / 255.0\n",
    "test_images=test_images / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q's reshape\n",
    "reshape 이라는게, 이미지가 현재 여러개로 구분이 되어있는데, reshape 을 통해서 1개의 tensor 라는 4D 형태로 묶음을 만들어 놓는 작업을 의미하는 것인가? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T05:32:53.735068Z",
     "start_time": "2021-07-13T05:29:19.911577Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 41s 689us/sample - loss: 0.4356 - accuracy: 0.8426\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 43s 716us/sample - loss: 0.2886 - accuracy: 0.8937\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 43s 709us/sample - loss: 0.2475 - accuracy: 0.9081\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 42s 705us/sample - loss: 0.2140 - accuracy: 0.9210\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 43s 714us/sample - loss: 0.1906 - accuracy: 0.9282\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.2491 - accuracy: 0.9093\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images.reshape(60000,28,28,1)\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images.reshape(10000,28,28,1)\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu', input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs = 5)\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://taewan.kim/post/cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution \n",
    "\n",
    "필터를 이용해서 특징을 뽑아 내는 것으로 이해하면 되는 것일까? \n",
    "\n",
    "\n",
    "# MaxPooling\n",
    "\n",
    "MaxPooling 을 통해서 pixel 안에서 제일 정보 값이 큰 놈들만 뽑아 내는 것이다. 이로인해서 그 이미지의 제일 특징적인 것을 뽑아 낼 수 있게 되는 것이다. 다른 Pooling 의 예시로는 Average Pooling 이 존재 한다. \n",
    "\n",
    "# Pooling \n",
    "\n",
    "1. input size를 줄임.\n",
    "     : 여러번 convolution layer을 반복하게 되는데, 별로 필요하지 않은 자료까지 전부를 다 분석할 필요가 없다. 특징만 뽑아내서, 학습하는 것이 합리적이지 않겠는가? \n",
    " \n",
    "2. overfitting을 조절\n",
    "     : input size가 줄어드는 것은 그만큼 쓸데없는 parameter의 수가 줄어드는 것이라고 생각할 수 있다. 훈련데이터에만 높은 성능을 보이는 과적합(overfitting)을 줄일 수 있다.\n",
    "       \n",
    "3. 특징을 잘 뽑아냄.\n",
    "     : pooling을 했을 때, 특정한 모양을 더 잘 인식할 수 있음.\n",
    "     \n",
    "# Convolution & Pooling\n",
    "\n",
    "특징 추출영역은 Filter 를 사용하여 공유 파라미터 수를 최소화 하면서 이미지의 특징을 찾는 Convolution 레이어와 특징을 강화하고 모으는 Pooling 레이어로 구성이 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolution(64, (3,3), activation = 'relu', input_shape)...\n",
    "\n",
    "conv filter 라는 것이 초기값 설정을 통해 무작위로 분포 하게 되지만 학습을 통해서 완성된 edge filter 로 만들어 지게 된다고 한다. \n",
    "정확하게 어떻게 생겨 먹은 것일까.... \n",
    "-> visualizing 하면서 알게 될 것이다. \n",
    "\n",
    "https://89douner.tistory.com/57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
