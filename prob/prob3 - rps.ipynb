{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d1d0a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T06:53:00.634815Z",
     "start_time": "2021-10-02T06:35:02.101251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2016 images belonging to 3 classes.\n",
      "Found 504 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-02 15:36:35.489989: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-10-02 15:36:35.513445: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa3cbf43790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-10-02 15:36:35.513460: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "101/101 [==============================] - 33s 323ms/step - loss: 0.5666 - acc: 0.7877 - val_loss: 0.4464 - val_acc: 0.7500\n",
      "Epoch 2/30\n",
      "101/101 [==============================] - 31s 309ms/step - loss: 0.0688 - acc: 0.9846 - val_loss: 0.6251 - val_acc: 0.6925\n",
      "Epoch 3/30\n",
      "101/101 [==============================] - 31s 309ms/step - loss: 0.0182 - acc: 0.9955 - val_loss: 0.6656 - val_acc: 0.6786\n",
      "Epoch 4/30\n",
      "101/101 [==============================] - 32s 316ms/step - loss: 0.0336 - acc: 0.9945 - val_loss: 0.4845 - val_acc: 0.7520\n",
      "Epoch 5/30\n",
      "101/101 [==============================] - 32s 315ms/step - loss: 0.0036 - acc: 0.9995 - val_loss: 0.6330 - val_acc: 0.7361\n",
      "Epoch 6/30\n",
      "101/101 [==============================] - 33s 330ms/step - loss: 0.0087 - acc: 0.9985 - val_loss: 0.6994 - val_acc: 0.7202\n",
      "Epoch 7/30\n",
      "101/101 [==============================] - 32s 316ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.4926 - val_acc: 0.7758\n",
      "Epoch 8/30\n",
      "101/101 [==============================] - 32s 321ms/step - loss: 9.6488e-04 - acc: 0.9995 - val_loss: 0.4567 - val_acc: 0.8016\n",
      "Epoch 9/30\n",
      "101/101 [==============================] - 33s 328ms/step - loss: 0.0041 - acc: 0.9975 - val_loss: 0.3409 - val_acc: 0.8214\n",
      "Epoch 10/30\n",
      "101/101 [==============================] - 35s 348ms/step - loss: 3.8170e-05 - acc: 1.0000 - val_loss: 0.8005 - val_acc: 0.7579\n",
      "Epoch 11/30\n",
      "101/101 [==============================] - 33s 327ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.4976 - val_acc: 0.8115\n",
      "Epoch 12/30\n",
      "101/101 [==============================] - 31s 306ms/step - loss: 2.6502e-06 - acc: 1.0000 - val_loss: 0.8690 - val_acc: 0.7579\n",
      "Epoch 13/30\n",
      "101/101 [==============================] - 32s 319ms/step - loss: 0.0011 - acc: 0.9990 - val_loss: 0.8981 - val_acc: 0.7540\n",
      "Epoch 14/30\n",
      "101/101 [==============================] - 32s 317ms/step - loss: 8.4834e-07 - acc: 1.0000 - val_loss: 0.6611 - val_acc: 0.7996\n",
      "Epoch 15/30\n",
      "101/101 [==============================] - 31s 310ms/step - loss: 2.9855e-04 - acc: 1.0000 - val_loss: 0.4286 - val_acc: 0.8254\n",
      "Epoch 16/30\n",
      "101/101 [==============================] - 31s 311ms/step - loss: 1.2587e-06 - acc: 1.0000 - val_loss: 0.5862 - val_acc: 0.8115\n",
      "Epoch 17/30\n",
      "101/101 [==============================] - 31s 306ms/step - loss: 5.0557e-08 - acc: 1.0000 - val_loss: 1.0172 - val_acc: 0.7639\n",
      "Epoch 18/30\n",
      "101/101 [==============================] - 31s 309ms/step - loss: 9.8158e-09 - acc: 1.0000 - val_loss: 1.1420 - val_acc: 0.7560\n",
      "Epoch 19/30\n",
      "101/101 [==============================] - 31s 312ms/step - loss: 4.3757e-09 - acc: 1.0000 - val_loss: 1.0010 - val_acc: 0.7738\n",
      "Epoch 20/30\n",
      "101/101 [==============================] - 32s 313ms/step - loss: 2.9566e-09 - acc: 1.0000 - val_loss: 1.0417 - val_acc: 0.7698\n",
      "Epoch 21/30\n",
      "101/101 [==============================] - 31s 310ms/step - loss: 1.9513e-09 - acc: 1.0000 - val_loss: 1.0890 - val_acc: 0.7639\n",
      "Epoch 22/30\n",
      "101/101 [==============================] - 34s 338ms/step - loss: 1.3600e-09 - acc: 1.0000 - val_loss: 1.1170 - val_acc: 0.7619\n",
      "Epoch 23/30\n",
      "101/101 [==============================] - 35s 348ms/step - loss: 1.2418e-09 - acc: 1.0000 - val_loss: 1.1351 - val_acc: 0.7639\n",
      "Epoch 24/30\n",
      "101/101 [==============================] - 34s 333ms/step - loss: 8.2784e-10 - acc: 1.0000 - val_loss: 1.1368 - val_acc: 0.7619\n",
      "Epoch 25/30\n",
      "101/101 [==============================] - 34s 334ms/step - loss: 7.0958e-10 - acc: 1.0000 - val_loss: 1.1353 - val_acc: 0.7619\n",
      "Epoch 26/30\n",
      "101/101 [==============================] - 32s 320ms/step - loss: 7.6871e-10 - acc: 1.0000 - val_loss: 1.1508 - val_acc: 0.7619\n",
      "Epoch 27/30\n",
      "101/101 [==============================] - 32s 317ms/step - loss: 6.5045e-10 - acc: 1.0000 - val_loss: 1.1562 - val_acc: 0.7619\n",
      "Epoch 28/30\n",
      "101/101 [==============================] - 32s 317ms/step - loss: 5.3218e-10 - acc: 1.0000 - val_loss: 1.1698 - val_acc: 0.7619\n",
      "Epoch 29/30\n",
      "101/101 [==============================] - 33s 325ms/step - loss: 4.1392e-10 - acc: 1.0000 - val_loss: 1.1533 - val_acc: 0.7619\n",
      "Epoch 30/30\n",
      "101/101 [==============================] - 34s 338ms/step - loss: 4.1392e-10 - acc: 1.0000 - val_loss: 1.1697 - val_acc: 0.7619\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this test with increasing difficulty from 1-5\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score much less\n",
    "# than your Category 5 question.\n",
    "# ======================================================================\n",
    "#\n",
    "# Computer Vision with CNNs\n",
    "#\n",
    "# For this task you will build a classifier for Rock-Paper-Scissors \n",
    "# based on the rps dataset.\n",
    "#\n",
    "# IMPORTANT: Your final layer should be as shown, do not change the\n",
    "# provided code, or the tests may fail\n",
    "#\n",
    "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
    "# So ensure that your input layer is designed accordingly, or the tests\n",
    "# may fail. \n",
    "#\n",
    "# NOTE THAT THIS IS UNLABELLED DATA. \n",
    "# You can use the ImageDataGenerator to automatically label it\n",
    "# and we have provided some starter code.\n",
    "\n",
    "# =========== 합격 기준 가이드라인 공유 ============= #\n",
    "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
    "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
    "# =================================================== #\n",
    "# 문제명: Category 3 - rps\n",
    "# val_loss: 0.0871\n",
    "# val_acc: 0.97\n",
    "# =================================================== #\n",
    "# =================================================== #\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def solution_model():\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
    "    urllib.request.urlretrieve(url, 'rps.zip')\n",
    "    local_zip = 'rps.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('tmp/')\n",
    "    zip_ref.close()\n",
    "\n",
    "\n",
    "    TRAINING_DIR = \"tmp/rps/\"\n",
    "    training_datagen = ImageDataGenerator( rescale = 1./255, validation_split = 0.2)\n",
    "    # YOUR CODE HERE)\n",
    "\n",
    "\n",
    "\n",
    "    train_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                       target_size=(150, 150), \n",
    "                                                       batch_size=20, \n",
    "                                                       class_mode='categorical', \n",
    "                                                       subset='training',\n",
    "                                                      )\n",
    "    validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                            target_size=(150, 150), \n",
    "                                                            batch_size=20, \n",
    "                                                            class_mode='categorical',\n",
    "                                                            subset='validation',\n",
    "                                                           )\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(150, 150, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2), \n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2), \n",
    "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2), \n",
    "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2), \n",
    "      tf.keras.layers.Flatten(), \n",
    "      tf.keras.layers.Dense(512, activation='relu'),                                       \n",
    "\n",
    "\n",
    "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    model.fit(\n",
    "      train_generator, \n",
    "      steps_per_epoch=len(train_generator),\n",
    "      epochs=30,\n",
    "      validation_data=(validation_generator),\n",
    "      validation_steps=len(validation_generator)\n",
    "    )\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this\n",
    "# This .h5 will be uploaded to the testing infrastructure\n",
    "# and a score will be returned to you\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"TF3-rps.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785278c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
