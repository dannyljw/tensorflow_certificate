{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5364d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T05:49:22.749131Z",
     "start_time": "2021-10-02T05:41:13.944117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-02 14:41:17.621235: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-10-02 14:41:17.634553: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdaf38889e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-10-02 14:41:17.634567: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9355\n",
      "Epoch 00001: val_loss improved from inf to 0.14485, saving model to my_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2160 - acc: 0.9355 - val_loss: 0.1449 - val_acc: 0.9600\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.1038 - acc: 0.9703\n",
      "Epoch 00002: val_loss improved from 0.14485 to 0.13711, saving model to my_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1038 - acc: 0.9703 - val_loss: 0.1371 - val_acc: 0.9610\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0760 - acc: 0.9788\n",
      "Epoch 00003: val_loss improved from 0.13711 to 0.08846, saving model to my_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0760 - acc: 0.9788 - val_loss: 0.0885 - val_acc: 0.9778\n",
      "Epoch 4/20\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9829\n",
      "Epoch 00004: val_loss improved from 0.08846 to 0.07884, saving model to my_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0579 - acc: 0.9829 - val_loss: 0.0788 - val_acc: 0.9783\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0489 - acc: 0.9863\n",
      "Epoch 00005: val_loss did not improve from 0.07884\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0489 - acc: 0.9863 - val_loss: 0.0811 - val_acc: 0.9807\n",
      "Epoch 6/20\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9882\n",
      "Epoch 00006: val_loss improved from 0.07884 to 0.07302, saving model to my_checkpoint.ckpt\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0424 - acc: 0.9882 - val_loss: 0.0730 - val_acc: 0.9811\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0364 - acc: 0.9900\n",
      "Epoch 00007: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0364 - acc: 0.9900 - val_loss: 0.1096 - val_acc: 0.9749\n",
      "Epoch 8/20\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9910\n",
      "Epoch 00008: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0319 - acc: 0.9910 - val_loss: 0.0741 - val_acc: 0.9826\n",
      "Epoch 9/20\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9918\n",
      "Epoch 00009: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0309 - acc: 0.9918 - val_loss: 0.0790 - val_acc: 0.9823\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0276 - acc: 0.9928\n",
      "Epoch 00010: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0276 - acc: 0.9928 - val_loss: 0.1079 - val_acc: 0.9827\n",
      "Epoch 11/20\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9935\n",
      "Epoch 00011: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0262 - acc: 0.9934 - val_loss: 0.0901 - val_acc: 0.9805\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0229 - acc: 0.9938\n",
      "Epoch 00012: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0229 - acc: 0.9938 - val_loss: 0.1010 - val_acc: 0.9802\n",
      "Epoch 13/20\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9946\n",
      "Epoch 00013: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0218 - acc: 0.9946 - val_loss: 0.1092 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9942\n",
      "Epoch 00014: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0228 - acc: 0.9942 - val_loss: 0.1076 - val_acc: 0.9811\n",
      "Epoch 15/20\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9955\n",
      "Epoch 00015: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0194 - acc: 0.9955 - val_loss: 0.1029 - val_acc: 0.9825\n",
      "Epoch 16/20\n",
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9956\n",
      "Epoch 00016: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 0.0184 - acc: 0.9956 - val_loss: 0.1279 - val_acc: 0.9820\n",
      "Epoch 17/20\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9953\n",
      "Epoch 00017: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0231 - acc: 0.9953 - val_loss: 0.1251 - val_acc: 0.9785\n",
      "Epoch 18/20\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9967\n",
      "Epoch 00018: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0149 - acc: 0.9966 - val_loss: 0.1005 - val_acc: 0.9825\n",
      "Epoch 19/20\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9963\n",
      "Epoch 00019: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0148 - acc: 0.9963 - val_loss: 0.1955 - val_acc: 0.9807\n",
      "Epoch 20/20\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9961\n",
      "Epoch 00020: val_loss did not improve from 0.07302\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0235 - acc: 0.9961 - val_loss: 0.1078 - val_acc: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this test with increasing difficulty from 1-5\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score much less\n",
    "# than your Category 5 question.\n",
    "# ======================================================================\n",
    "#\n",
    "# Basic Datasets Question\n",
    "#\n",
    "# Create a classifier for the MNIST dataset\n",
    "# Note that the test will expect it to classify 10 classes and that the \n",
    "# input shape should be the native size of the MNIST dataset which is \n",
    "# 28x28 monochrome. Do not resize the data. Your input layer should accept\n",
    "# (28,28) as the input shape only. If you amend this, the tests will fail.\n",
    "#\n",
    "\n",
    "# =================================================== #\n",
    "\n",
    "# =========== 합격 기준 가이드라인 공유 ============= #\n",
    "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
    "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
    "# =================================================== #\n",
    "# 문제명: Category 2 - mnist\n",
    "# val_loss: 0.07\n",
    "# val_acc: 0.97\n",
    "# =================================================== #\n",
    "# =================================================== #\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "def solution_model():\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "    x_train = x_train / 255.0\n",
    "    x_valid = x_valid / 255.0\n",
    "\n",
    "    model = Sequential([\n",
    "        # Flatten으로 shape 펼치기\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        # Dense Layer\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        # Classification을 위한 Softmax \n",
    "        Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    checkpoint_path = \"my_checkpoint.ckpt\"\n",
    "    checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                save_weights_only=True, \n",
    "                                save_best_only=True, \n",
    "                                monitor='val_loss', \n",
    "                                verbose=1)\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_valid, y_valid),\n",
    "                        epochs=20,\n",
    "                        callbacks=[checkpoint],\n",
    "                      )\n",
    "\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this\n",
    "# This .h5 will be uploaded to the testing infrastructure\n",
    "# and a score will be returned to you\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"TF2-mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd8167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
